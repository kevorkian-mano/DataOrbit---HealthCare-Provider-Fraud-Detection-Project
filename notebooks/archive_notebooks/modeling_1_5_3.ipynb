{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1 â€” Load & Inspect Dataset\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load your dataset (adjust filename if needed)\n",
        "df = pd.read_csv(\"provider_features.csv\")\n",
        "\n",
        "# Basic overview\n",
        "print(\"Number of samples:\", df.shape[0])\n",
        "print(\"Number of features:\", df.shape[1])\n",
        "print(\"\\nDataset head:\\n\", df.head())\n",
        "\n",
        "# Check class imbalance\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df['PotentialFraud'].value_counts(normalize=True))\n",
        "\n",
        "# Separate data types\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "numeric_cols = df.select_dtypes(include=['int64','float64']).columns\n",
        "\n",
        "print(\"\\nCategorical Columns:\", list(categorical_cols))\n",
        "print(\"Numeric Columns:\", list(numeric_cols))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFYlQtIhjZnd",
        "outputId": "57fd0aeb-2f6f-4c22-ef19-9760347739d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 5410\n",
            "Number of features: 35\n",
            "\n",
            "Dataset head:\n",
            "    Provider  ClaimCount  total_reimbursed  mean_claim_amount  \\\n",
            "0  PRV51001        24.0          104340.0        4347.500000   \n",
            "1  PRV51003       132.0          605670.0        4588.409091   \n",
            "2  PRV51004       143.0           51830.0         362.447552   \n",
            "3  PRV51005      1149.0          278960.0         242.785030   \n",
            "4  PRV51007        72.0           33710.0         468.194444   \n",
            "\n",
            "   max_claim_amount  InpatientReimbursement  OutpatientReimbursement  \\\n",
            "0           42000.0                 97000.0                   7340.0   \n",
            "1           57000.0                573000.0                  32670.0   \n",
            "2            3300.0                     0.0                  51830.0   \n",
            "3            4080.0                     0.0                 278960.0   \n",
            "4           10000.0                 19000.0                  14710.0   \n",
            "\n",
            "   Inp_Outp_Reimbursement_Ratio     AvgAge  PercDeceased  ...  \\\n",
            "0                     13.215259  78.750000           0.0  ...   \n",
            "1                     17.539027  69.083333           0.0  ...   \n",
            "2                      0.000000  71.307692           0.0  ...   \n",
            "3                      0.000000  69.519582           0.0  ...   \n",
            "4                      1.291638  68.305556           0.0  ...   \n",
            "\n",
            "   MaxMonthlyClaimCount  TotalReimbursementOverall  AvgMonthlyReimbursement  \\\n",
            "0                   5.0                   104340.0             11593.333333   \n",
            "1                  16.0                   605670.0             46590.000000   \n",
            "2                  18.0                    51830.0              4319.166667   \n",
            "3                 112.0                   278960.0             21458.461538   \n",
            "4                   9.0                    33710.0              2809.166667   \n",
            "\n",
            "   MaxMonthlyReimbursement  UniqueAttendingPhysicians  \\\n",
            "0                  55000.0                       13.0   \n",
            "1                 128550.0                       44.0   \n",
            "2                   7340.0                       37.0   \n",
            "3                  34370.0                        6.0   \n",
            "4                  11710.0                       10.0   \n",
            "\n",
            "   UniqueOperatingPhysicians  UniqueOtherPhysicians  UniqueStates  \\\n",
            "0                        2.0                    7.0           1.0   \n",
            "1                        2.0                   22.0           3.0   \n",
            "2                        0.0                   25.0           9.0   \n",
            "3                        0.0                    4.0           4.0   \n",
            "4                        1.0                    7.0           2.0   \n",
            "\n",
            "   UniqueCounties  PotentialFraud  \n",
            "0             7.0              No  \n",
            "1            23.0             Yes  \n",
            "2            27.0              No  \n",
            "3            26.0             Yes  \n",
            "4             6.0              No  \n",
            "\n",
            "[5 rows x 35 columns]\n",
            "\n",
            "Class distribution:\n",
            "PotentialFraud\n",
            "No     0.90647\n",
            "Yes    0.09353\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Categorical Columns: ['Provider', 'PotentialFraud']\n",
            "Numeric Columns: ['ClaimCount', 'total_reimbursed', 'mean_claim_amount', 'max_claim_amount', 'InpatientReimbursement', 'OutpatientReimbursement', 'Inp_Outp_Reimbursement_Ratio', 'AvgAge', 'PercDeceased', 'Avg_ChronicCond_Alzheimer', 'Avg_ChronicCond_Heartfailure', 'Avg_ChronicCond_KidneyDisease', 'Avg_ChronicCond_Cancer', 'Avg_ChronicCond_ObstrPulmonary', 'Avg_ChronicCond_Depression', 'Avg_ChronicCond_Diabetes', 'Avg_ChronicCond_IschemicHeart', 'Avg_ChronicCond_Osteoporasis', 'Avg_ChronicCond_rheumatoidarthritis', 'Avg_ChronicCond_stroke', 'UniqueDiagnosisCodeCount', 'UniqueProcedureCodeCount', 'TotalClaimCount', 'AvgMonthlyClaimCount', 'MaxMonthlyClaimCount', 'TotalReimbursementOverall', 'AvgMonthlyReimbursement', 'MaxMonthlyReimbursement', 'UniqueAttendingPhysicians', 'UniqueOperatingPhysicians', 'UniqueOtherPhysicians', 'UniqueStates', 'UniqueCounties']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Samples: 5,410\n",
        "\n",
        "Features: 35 (mostly numeric, 2 categorical)\n",
        "\n",
        "Target imbalance:\n",
        "\n",
        "No Fraud: 90.6%\n",
        "\n",
        "Fraud: 9.3% â†’ highly imbalanced\n",
        "\n",
        "Data types:\n",
        "\n",
        "Categorical: Provider, PotentialFraud\n",
        "\n",
        "Numeric: 33 numeric features\n",
        "\n",
        "Dataset size: Medium â€” suitable for tree-based models, LR, SVM\n",
        "\n",
        "Patterns: Fraud is expected to be nonlinear and complex"
      ],
      "metadata": {
        "id": "tJC2dZGtlf_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is:\n",
        "\n",
        "Medium-sized â†’ all ML models can run efficiently\n",
        "\n",
        "Highly imbalanced â†’ need models that handle imbalance or can use class weights\n",
        "\n",
        "Mostly numeric â†’ very little preprocessing is required\n",
        "\n",
        "Contains only one meaningful categorical feature: Provider"
      ],
      "metadata": {
        "id": "ZegixxiEmHZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree\n",
        "\n",
        "Decision Trees create hierarchical rules by splitting features at thresholds.\n",
        "They naturally handle nonlinear fraud patterns and require almost no preprocessing.\n",
        "However, they can overfit, especially with imbalance like our dataset.\n",
        "\n",
        "Fit for the dataset?\n",
        "\n",
        "âœ” Minimal preprocessing\n",
        "\n",
        "âœ” Handles mixed data\n",
        "\n",
        "âœ˜ Weak on imbalanced classes\n",
        "\n",
        "âœ˜ High variance"
      ],
      "metadata": {
        "id": "ytYBaGXnnCAB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest\n",
        "\n",
        "Random Forest trains many trees and averages them to reduce overfitting.\n",
        "It handles nonlinear relationships and mixed numeric/categorical data very well.\n",
        "It also handles class imbalance better than single trees, especially with class weights.\n",
        "\n",
        "Fit for the dataset?\n",
        "\n",
        "âœ” Excellent with numeric-heavy data\n",
        "\n",
        "âœ” Robust to imbalance\n",
        "\n",
        "âœ” Captures complex fraud patterns\n",
        "\n",
        "âœ˜ Less interpretable\n",
        "\n",
        "âœ˜ Slower than Logistic Regression (but still manageable)"
      ],
      "metadata": {
        "id": "gKcAm-3JnKSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting (XGBoost / LightGBM / CatBoost)\n",
        "\n",
        "Gradient Boosting builds trees sequentially to correct previous errors.\n",
        "It performs exceptionally well on tabular, imbalanced, nonlinear datasets â€” like ours.\n",
        "Modern implementations handle imbalance directly (e.g., scale_pos_weight).\n",
        "\n",
        "Fit for the dataset?\n",
        "\n",
        "âœ” Best for nonlinear and sparse fraud patterns\n",
        "\n",
        "âœ” Handles imbalance very well\n",
        "\n",
        "âœ” Works great with numeric features\n",
        "\n",
        "âœ˜ Slower training\n",
        "\n",
        "âœ˜ Less interpretable"
      ],
      "metadata": {
        "id": "l3pNRHkrnX2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression\n",
        "\n",
        "Logistic Regression is a linear classifier with high interpretability and fast training.\n",
        "However, it assumes linear relationships and depends heavily on preprocessing.\n",
        "Fraud detection is not linear, and the dataset has complex numeric interactions.\n",
        "\n",
        "Fit for the dataset?\n",
        "\n",
        "âœ” Very fast\n",
        "\n",
        "âœ” Highly interpretable\n",
        "\n",
        "âœ˜ Performs poorly on nonlinear fraud patterns\n",
        "\n",
        "âœ˜ Needs preprocessing (scaling, encoding)"
      ],
      "metadata": {
        "id": "tmfKtH6rnjna"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machine (SVM)\n",
        "\n",
        "SVM separates fraud vs non-fraud using an optimal boundary (hyperplane).\n",
        "Kernel SVMs can model nonlinear patterns but do not scale well on datasets >3000 rows.\n",
        "Our dataset (5410 rows Ã— 35 features) is borderline for SVM.\n",
        "\n",
        "Fit for your dataset?\n",
        "\n",
        "âœ” Works well with nonlinear boundaries\n",
        "\n",
        "âœ˜ Requires scaling of all features\n",
        "\n",
        "âœ˜ Slow on medium datasets\n",
        "\n",
        "âœ˜ Sensitive to imbalance (needs class weights)"
      ],
      "metadata": {
        "id": "LNTnGV79nxPg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on our dataset, the best primary model is:\n",
        "\n",
        "ðŸŽ¯ Gradient Boosting (XGBoost or LightGBM)"
      ],
      "metadata": {
        "id": "B1Y6TQOKn68B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting is chosen as the main model because:\n",
        "\n",
        "Our dataset is highly imbalanced (9% fraud), and Gradient Boosting algorithms handle this extremely well using scale_pos_weight or built-in imbalance handling.\n",
        "\n",
        "Fraud detection typically requires capturing nonlinear interactions between numeric features, which boosting models excel at.\n",
        "\n",
        "With 35 features (mostly numeric), the dataset is ideal for tree-based boosting.\n",
        "\n",
        "Gradient Boosting consistently outperforms simple models like Logistic Regression on fraud datasets.\n",
        "\n",
        "Training time is manageable with 5,410 samples."
      ],
      "metadata": {
        "id": "WJiqe7vpoDwL"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}